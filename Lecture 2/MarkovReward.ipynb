{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Markov Reward Processes\n",
    "\n",
    "Markov Reward Processes are essentially just Markov chain, but every time the agent leaves a state it gets a reward.\n",
    "\n",
    "<img src=\"/files/markov_reward_process.png\", width=500px>\n",
    "\n",
    "The gamma-weighted sum of all rewards for a single trajectory is called the return:\n",
    "\n",
    "<img src=\"/files/return.png\", width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy.random import choice\n",
    "import numpy as np\n",
    "\n",
    "state_names = [\"C1\", \"C2\", \"C3\", \"Pass\", \"Pub\", \"FB\", \"Sleep\"]\n",
    "\n",
    "p_matrix = [[0, .5, 0, 0, 0, .5, 0],\n",
    "            [0, 0, .8, 0, 0, 0, .2],\n",
    "            [0, 0, 0, .6, .4, 0, 0],\n",
    "            [0, 0, 0, 0, 0, 0, 1],\n",
    "            [.2, .4, .4, 0, 0, 0, 0],\n",
    "            [.1, 0, 0, 0, 0, .9, 0],\n",
    "            [0, 0, 0, 0, 0, 0, 0]]\n",
    "\n",
    "_rewards = [-2, -2, -2, 10, 1, -1, 0]\n",
    "\n",
    "# Just cus\n",
    "class ProbabilityMatrixException(Exception):\n",
    "    def __init__(self, message):\n",
    "        self.message = message\n",
    "    \n",
    "class RewardChain:\n",
    "    def __init__(self, p_matrix, rewards, state_names, terminal_index=6):\n",
    "        self.p_matrix = p_matrix\n",
    "        self.state_names = state_names\n",
    "        self.terminal_index = terminal_index\n",
    "        self.rewards = rewards\n",
    "        \n",
    "        assert (len(set([len(row) for row in p_matrix])) == 1), \"p_matrix rows must have equal lengths!\"\n",
    "        assert len(p_matrix[0]) == len(p_matrix), \"p_matrix must be square!\"\n",
    "        assert (len(self.rewards) == len(p_matrix)), \"rewards must be same length as p_matrix\"\n",
    "    \n",
    "    # Generates a random path through the chain\n",
    "    def sample(self, start_state):\n",
    "        path = []\n",
    "        if isinstance(start_state, str):\n",
    "            start_indx = self.state_names.index(start_state)\n",
    "        else:\n",
    "            start_indx = start_state\n",
    "            \n",
    "        state = start_indx\n",
    "        \n",
    "        while state != self.terminal_index:\n",
    "            path.append(state)\n",
    "            transition_p = self.p_matrix[state]\n",
    "            \n",
    "            # numpy.random.choice accepts choices (states 0 through len(p_matrix)) and\n",
    "            # equally sized list of probabilities for those choices\n",
    "            next_state = choice(range(len(self.p_matrix)), p=transition_p)\n",
    "            state = next_state\n",
    "        \n",
    "        path.append(self.terminal_index)\n",
    "        \n",
    "        if isinstance(start_state, str):\n",
    "            return self.pretty(path)\n",
    "        else:\n",
    "            return path\n",
    "    \n",
    "    \n",
    "    def pretty(self, path):\n",
    "        return [self.state_names[i] for i in path]\n",
    "    \n",
    "    \n",
    "    def G(self, path, gamma):\n",
    "        str_check = [isinstance(x, str) for x in path]\n",
    "        if any(str_check):\n",
    "            assert all(str_check), \"Path must be all int or all string\"\n",
    "            path = [self.state_names.index(x) for x in path]\n",
    "        \n",
    "        counter = 0\n",
    "        reward = 0\n",
    "        for state in path:\n",
    "            r = self.rewards[state] * (gamma**counter)\n",
    "            reward += (self.rewards[state] * (gamma**counter))\n",
    "            counter += 1\n",
    "        return reward\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return:  -20\n"
     ]
    }
   ],
   "source": [
    "chain = RewardChain(p_matrix, _rewards, state_names)\n",
    "path = chain.sample(\"C1\")\n",
    "print(\"Return: \", chain.G(path, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Return\n",
    "\n",
    "Since the return from any single trajectory is a random value, we can ask what the *expected* return is for a given state. This expectation is called the **value function**\n",
    "\n",
    "<img src=\"/files/mrp_value_function.png\", width=500px>\n",
    "\n",
    "A rough estimate of a state's value function can be calculated by taking many samples and averaging the return from each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Return for C1: -12.18\n"
     ]
    }
   ],
   "source": [
    "# Single state estimate\n",
    "\n",
    "rewards = []\n",
    "state = \"C1\"\n",
    "gamma = 1\n",
    "for i in range(0, 1000):\n",
    "    path = chain.sample(state)\n",
    "    reward = chain.G(path, gamma)\n",
    "    rewards.append(reward)\n",
    "\n",
    "print('Average Return for {0}: {1:.2f}'.format(state, np.mean(rewards)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C1': -12.49614,\n",
       " 'C2': 1.43329,\n",
       " 'C3': 4.3600300000000001,\n",
       " 'FB': -22.6419,\n",
       " 'Pass': 10.0,\n",
       " 'Pub': 0.82921999999999996,\n",
       " 'Sleep': 0.0}"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimate for all states\n",
    "\n",
    "# iterations = 100000\n",
    "iterations = 5000\n",
    "\n",
    "states = np.zeros(len(p_matrix))\n",
    "for state in range(len(states)):\n",
    "    rewards = []\n",
    "    for i in range(0, iterations):\n",
    "        path = chain.sample(state)\n",
    "        reward = chain.G(path, 1)\n",
    "        rewards.append(reward)\n",
    "    \n",
    "    states[state] = np.mean(rewards)\n",
    "\n",
    "{state_names[j]: states[j] for j in range(len(p_matrix))}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the Value Function Analytically\n",
    "\n",
    "The value function (also known as the bellman equation) can be solved for analytically with a little bit of linear algebra.\n",
    "\n",
    "<img src=\"/files/analytical_solution_1.png\", width=200px>\n",
    "<img src=\"/files/analytical_solution_2.png\", width=300px>\n",
    "<img src=\"/files/analytical_solution_3.png\", width=200px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1 -12.543209876543214\n",
      "C2 1.4567901234567908\n",
      "C3 4.320987654320986\n",
      "Pass 10.0\n",
      "Pub 0.8024691358024683\n",
      "FB -22.543209876543223\n",
      "Sleep 0.0\n"
     ]
    }
   ],
   "source": [
    "gamma = 1\n",
    "R = np.array(_rewards)\n",
    "P = np.matrix(p_matrix)\n",
    "I = np.identity(len(p_matrix))\n",
    "\n",
    "solution = np.dot(np.linalg.inv((I-gamma*P)), R)\n",
    "solution = solution.tolist()[0]\n",
    "for state in range(len(state_names)):\n",
    "    print(state_names[state], solution[state])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Comparing Solution vs. Sampling Estimates\n",
    "\n",
    "Comparing our sampled estimates with the closed-form solution, it looks like we get pretty close. Try increasing the `iteration` variable to some high number (and potentially wait a really long time) and see how close you can get it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSampling\tSolution\n",
      "\t--------\t--------\n",
      "C1:\t-12.496\t\t-12.543\n",
      "C2:\t1.433\t\t1.457\n",
      "C3:\t4.360\t\t4.321\n",
      "Pass:\t10.000\t\t10.000\n",
      "Pub:\t0.829\t\t0.802\n",
      "FB:\t-22.642\t\t-22.543\n",
      "Sleep:\t0.000\t\t0.000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\tSampling\\tSolution\")\n",
    "print(\"\\t--------\\t--------\")\n",
    "for j in range(len(states)):\n",
    "    print(\"{state}:\\t{0:0.3f}\\t\\t{1:0.3f}\".format(states[j], solution[j], state=state_names[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
